# PYTHON FRAMEWORK FOR VISULAIZING GRADIENT DESCENT DYNAMICS ON A LOSS SURFACE
 1) Developed a modular Python framework to simulate and visualize gradient descent algorithms (Vanilla,
    Momentum & Nag) on loss surfaces
 2) Designed support for multiple activation functions (sigmoid, linear) and loss functions (cross entropy,
    squared error loss) for model classification and regression tasks
 3) Integrated adaptive learning rate optimizers (Adam, RMSProp, AdaGrad) with dynamic batch modes (Batch,
    Mini Batch and Stochastic) for scalable optimization
 4) Animated 2D contour and 3D surface plots to illustrate optimizer trajectories and convergence dynamics.
